[package]
name = "vecboost"
version = "0.1.2"
edition = "2024"
authors = ["Kirky-X <kirky-x@outlook.com>"]
description = "High-performance embedding vector service written in Rust"
repository = "https://github.com/Kirky-X/vecboost"
documentation = "https://github.com/Kirky-X/vecboost"
homepage = "https://github.com/Kirky-X/vecboost"
license = "MIT"
keywords = ["embedding", "vector", "ml", "ai", "inference"]
categories = ["asynchronous", "science", "web-programming::http-server"]

[dependencies]
# Web Framework
axum = "0.7"
axum-extra = { version = "0.9", features = ["typed-header"] }
tokio = { version = "1.40", features = ["full"] }
tower-http = { version = "0.6", features = ["trace", "cors", "add-extension", "validate-request", "set-header", "timeout"] }

# gRPC support
tonic = "0.12"
prost = "0.13"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# OpenAPI Documentation
utoipa = { version = "5.1", features = ["axum_extras", "chrono", "uuid"] }
utoipa-swagger-ui = { version = "8.0", features = ["axum"] }
uuid = { version = "1.11", features = ["v4", "serde"] }

# Monitoring
prometheus = { version = "0.13", features = ["process"] }
axum-prometheus = "0.7"

# Rate Limiting
async-trait = "0.1"
redis = { version = "1.0.0-rc.5", optional = true, features = ["tokio-comp", "connection-manager"] }

# Configuration
config = "0.14"
toml = "0.8"

# Logging & Tracing
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Error Handling
thiserror = "2.0"
anyhow = "1.0"

# AI & Math
candle-core = { version = "0.9", features = [] }
candle-nn = "0.9"
candle-transformers = "0.9"
hf-hub = "0.3"

# Utilities
ndarray = { version = "0.16", optional = true }
ort = { version = "2.0.0-rc.11", optional = true }

# Utilities
tempfile = "3.14"
futures = "0.3"
sys-info = "0.9"
num_cpus = "1.16"
lru = "0.12"
hashbrown = "0.15"
xxhash-rust = { version = "0.8", features = ["xxh3"] }
chrono = { version = "0.4", features = ["serde"] }
regex = "1.11"
home = "0.5"
reqwest = { version = "0.12", features = ["stream"] }
sha2 = "0.10"
jsonwebtoken = "9.3"
password-hash = { version = "0.5", features = ["rand_core"] }
argon2 = "0.5"
rand = "0.8"
aes-gcm = "0.10"
hex = "0.4"

# CUDA support - only available on Linux with CUDA toolkit
cudarc = { version = "0.18.2", optional = true, default-features = false }

[build-dependencies]
tonic-build = "0.12"

[features]
default = []
cuda = ["candle-core/cuda", "candle-nn/cuda"]
onnx = ["ndarray", "ort"]
metal = ["candle-core/metal", "candle-nn/metal"]
grpc = []
redis = ["dep:redis"]
auth = []

# Platform-specific default features
# macOS defaults to metal support
[target.'cfg(target_os = "macos")'.dependencies]
tokenizers = { version = "0.15", features = ["http"] }

# Linux defaults to CUDA support
[target.'cfg(target_os = "linux")'.dependencies]
# Default to CUDA feature on Linux

# Windows defaults to CUDA support
[target.'cfg(target_os = "windows")'.dependencies]
# Default to CUDA feature on Windows

[profile.dev]
opt-level = 1

[[example]]
name = "gpu_basic_device_test"
path = "examples/gpu/basic_device_test.rs"
required-features = ["cuda"]

[[example]]
name = "gpu_candle_engine_test"
path = "examples/gpu/candle_engine_test.rs"
required-features = ["cuda"]

[[example]]
name = "gpu_onnx_engine_test"
path = "examples/gpu/onnx_engine_test.rs"
required-features = ["cuda", "onnx"]

[[example]]
name = "gpu_performance_comparison"
path = "examples/gpu/performance_comparison.rs"
required-features = ["cuda", "onnx"]