use std::path::PathBuf;
use vecboost::config::model::{DeviceType, EngineType, ModelConfig, Precision};
use vecboost::engine::candle_engine::CandleEngine;
use vecboost::engine::{AnyEngine, InferenceEngine};

mod utils;

#[cfg(feature = "onnx")]
fn run_onnx_test(
    model_path: &str,
    texts: &[String],
) -> Result<(Vec<Vec<f32>>, f64), Box<dyn std::error::Error>> {
    let model_config = ModelConfig {
        name: "bge-m3".to_string(),
        engine_type: EngineType::Onnx,
        model_path: PathBuf::from(model_path),
        tokenizer_path: None,
        device: DeviceType::Cuda,
        max_batch_size: 32,
        pooling_mode: None,
        expected_dimension: Some(1024),
        memory_limit_bytes: None,
        oom_fallback_enabled: false,
        model_sha256: None,
    };

    let mut engine = AnyEngine::new(&model_config, EngineType::Onnx, Precision::Fp32)?;
    let (embeddings, duration) = utils::measure_time(|| engine.embed_batch(texts))?;
    Ok((embeddings, duration))
}

fn run_candle_test(
    model_path: &str,
    texts: &[String],
) -> Result<(Vec<Vec<f32>>, f64), Box<dyn std::error::Error>> {
    let config = ModelConfig {
        name: "bge-m3".to_string(),
        engine_type: EngineType::Candle,
        model_path: PathBuf::from(model_path),
        tokenizer_path: None,
        device: DeviceType::Cuda,
        max_batch_size: 32,
        pooling_mode: None,
        expected_dimension: Some(1024),
        memory_limit_bytes: None,
        oom_fallback_enabled: false,
        model_sha256: None,
    };

    let engine = CandleEngine::new(&config, Precision::Fp16)?;
    let (embeddings, duration) = utils::measure_time(|| engine.embed_batch(texts))?;
    Ok((embeddings, duration))
}

#[cfg(feature = "onnx")]
fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸš€ GPU å¼•æ“æ€§èƒ½å¯¹æ¯”æµ‹è¯•");
    println!("=========================\n");

    if !utils::check_cuda_available() {
        println!("âŒ CUDA ä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿å·²å®‰è£… CUDA é©±åŠ¨å’Œ cuDNN");
        return Ok(());
    }

    let model_path = match utils::find_model_path(utils::DEFAULT_MODEL_PATHS) {
        Some(path) => path,
        None => {
            println!("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶");
            return Ok(());
        }
    };

    let texts = utils::get_test_texts();
    println!("ğŸ“Š æµ‹è¯•é…ç½®:");
    println!("  æ–‡æœ¬æ•°é‡: {}", texts.len());
    println!("  æ¨¡å‹è·¯å¾„: {}", model_path);

    println!("\nğŸ”§ æµ‹è¯• Candle å¼•æ“...");
    let (candle_embeddings, candle_duration) = run_candle_test(&model_path, &texts)?;
    let candle_metrics = utils::calculate_metrics(candle_duration, texts.len());
    utils::print_metrics(&candle_metrics, "Candle å¼•æ“");

    println!("\nğŸ”§ æµ‹è¯• ONNX Runtime å¼•æ“...");
    let (onnx_embeddings, onnx_duration) = run_onnx_test(&model_path, &texts)?;
    let onnx_metrics = utils::calculate_metrics(onnx_duration, texts.len());
    utils::print_metrics(&onnx_metrics, "ONNX Runtime å¼•æ“");

    println!("\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:");
    let speedup = onnx_duration / candle_duration;
    if speedup > 1.0 {
        println!("  Candle æ¯” ONNX å¿« {:.2}x", speedup);
    } else {
        println!("  ONNX æ¯” Candle å¿« {:.2}x", 1.0 / speedup);
    }

    println!("\nâœ… æ€§èƒ½å¯¹æ¯”æµ‹è¯•å®Œæˆ");
    Ok(())
}

#[cfg(not(feature = "onnx"))]
fn main() {
    println!("âŒ æ­¤ç¤ºä¾‹éœ€è¦å¯ç”¨ 'onnx' feature");
    println!("   è¿è¡Œå‘½ä»¤: cargo run --example performance_comparison --features onnx");
}
